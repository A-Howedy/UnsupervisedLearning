{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4957930a-3176-4243-b157-b6410950c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "407ff670-2cf0-488e-ba6e-c96b79481f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(exp_num):\n",
    "    print(f\"Data Set: Experiment{exp_num}\")\n",
    "    data_frame = pd.read_csv(f\"experiments/Experiment{exp_num}.txt\")\n",
    "    nom_assignments = data_frame['m']\n",
    "    new_df = data_frame.drop(['m'],axis=1)\n",
    "    gaus_data = new_df.to_numpy()\n",
    "    N,d = gaus_data.shape\n",
    "    return gaus_data, N, d, nom_assignments.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bc41d559-fb2f-4846-b27e-1d1aca6c12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_points(a, b):\n",
    "    try:\n",
    "        dim = len(b)\n",
    "        dim = len(a)\n",
    "    except TypeError:\n",
    "        return (a-b) * (a-b)\n",
    "    s = 0\n",
    "    for i in range(0, dim):\n",
    "        s+=(a[i] - b[i]) * (a[i] - b[i])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4530492-96a7-46c5-bacb-9ef9bb69da81",
   "metadata": {},
   "source": [
    "Expectation Maximization through Gaussian Mixture Modes. This method consists of two general steps. Step 1, E-step which involves \"guessing\" latent values. Step 2, M-step which updates parameters based on the previous guess.\n",
    "\n",
    "Model data by specifying Joint Distribution\n",
    "p(x(i), z(i)) = p(x(i) | z(i)) p(z(i))\n",
    "in which z(i) is sampled from Multinomial(phi) and x(i) is drawn from one of k Gaussians (Mixture of Gaussians!) which depend on some z(i).\n",
    "\n",
    "When modeling the data z(i) are latent variables, they indicate which Gaussian each point originated from.\n",
    "\n",
    "\n",
    "MLE -> Not possible to maximize in closed form\n",
    "\n",
    "parameters:\n",
    "weights (pi_k) -> act as \"soft\" assignments\n",
    "phi, mu, sigma\n",
    "\n",
    "E-Step -> Update weights using a fixed mean and covariance and determining best possible class for each x(i). Calculating the posterior probability of our parameters the z(i)'s, given a particular x(i) and set of parameters using Bayes Rule. Evaluate the density of a Gaussian with mu and sigma. Then determine p(z(i) = j) given a particular phi. \n",
    "\n",
    "The formula for calculating this posterior is\n",
    "\n",
    "FOR EACH J\n",
    "(density of Gaussian based on current mean_j and covariance_j) * (P(z(i) = j) / (SUMMATION OVER EACH CLASS l in k (Gaus_density based on l) * (p(z(i) = l))\n",
    "\n",
    "Now use the weights calculated in E and replace z(i) = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24b748f0-6636-44ae-883b-b305af74ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_of_pairs(mean_assignments, nominal_assignments):\n",
    "    #group nominal assignments\n",
    "    likelihoods = []\n",
    "    for cluster, data_idx in enumerate(mean_assignments):\n",
    "        same_source = 0\n",
    "        total_in_cluster = 0\n",
    "        #Split data_idx into two sublists and stack them\n",
    "        try:\n",
    "            sublists = np.split(np.array(data_idx), 2)\n",
    "        except ValueError:\n",
    "            data_idx.pop()\n",
    "            sublists = np.split(np.array(data_idx),2)\n",
    "         #stacking!\n",
    "        stacked_list = np.stack(sublists, axis=1)\n",
    "        #now compare the two nominal assignments\n",
    "        for pair in stacked_list:\n",
    "            #print(f\"pair {pair}, {assign[pair[0]]} == {assign[pair[1]]}\")\n",
    "            if nominal_assignments[pair[0]] == nominal_assignments[pair[1]]:\n",
    "                same_source += 1\n",
    "            total_in_cluster += 1\n",
    "        #print(f\"Cluster {cluster} | same sources {same_source} / {total_in_cluster}\")\n",
    "        if total_in_cluster == 0:\n",
    "            likelihoods.append(0)\n",
    "        else:\n",
    "            likelihoods.append(same_source/total_in_cluster)\n",
    "    return np.mean(likelihoods)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34815af7-200f-43e8-b822-bc4b9e2a5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, data, k, N, dim, n_iterations = 100):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.N = N\n",
    "        self.dimension = dim\n",
    "        self.n_iterations = n_iterations\n",
    "        self.run_weights = []\n",
    "        self.weight_total = []\n",
    "    \n",
    "    def calculate_posterior(self):\n",
    "        distributions = []\n",
    "        for i in range(0, self.k):\n",
    "            distributions.append(multivariate_normal(mean = self.mu[i], cov = self.sigma[i]).pdf(self.data))\n",
    "        gaus_densities = np.array(distributions).T\n",
    "        num = gaus_densities * self.phi\n",
    "        den = num.sum(axis=1)[:, np.newaxis]\n",
    "        return num/den\n",
    "    \n",
    "    def update_mean(self, weight, weight_sum):\n",
    "        #FOR EACH WEIGHT, multiply by the weight and take summation divided by the total weight\n",
    "        #h = (self.data * weight).sum(axis=0)/weight_total\n",
    "        weight_data = self.data * weight \n",
    "        return np.sum(weight_data, axis=0) / weight_sum\n",
    "    \n",
    "    def update_cov(self, weight, weight_sum):\n",
    "        #multiply weight by (data - mean)(data-mean)transposed divide by total weight\n",
    "        #NP COV MAKES A GREAT FUNCTION FOR THIS!\n",
    "        #A WEIGHTS ARE THE VECTOR WEIGHTS USED TO ASSIGN PROBABILITIES TO OBSERVATIONS!\n",
    "        #BIAS CORRECTS THE NORMALIZATION FEATURE\n",
    "        cov_matrix_weights = weight / weight_sum\n",
    "        x2 = np.cov(self.data.T, aweights = cov_matrix_weights.flatten(), bias=True)\n",
    "        return x2\n",
    "\n",
    "    def avg_means_over_runs(self, n_runs = 50):\n",
    "        for i in range(0, n_runs):\n",
    "            self.calculate_means()\n",
    "            self.mu.sort()\n",
    "            self.run_weights.append(self.mu)\n",
    "        return np.mean(self.run_weights, axis=0)\n",
    "    \n",
    "    def calculate_means(self):\n",
    "        #initialize phi and the covariance matrix, randomly initialize means, \n",
    "        self.phi = np.array([(1/self.k) for i in range(0,self.k)])\n",
    "        self.mu = random.sample(sorted(self.data), self.k)\n",
    "        self.sigma = [np.cov(self.data.T) for i in range(0, self.k)]\n",
    "        \n",
    "        for i in range(0, self.n_iterations):\n",
    "            self.weights = self.calculate_posterior()\n",
    "            #print(f\"WEIGHTS {self.weights.shape}\")\n",
    "            self.phi = np.mean(self.weights, axis = 0)\n",
    "            for j in range(0,self.k):\n",
    "                weight_j = self.weights[:,[j]]\n",
    "                sum_of_weight = np.sum(weight_j)\n",
    "                self.mu[j] = self.update_mean(weight_j, sum_of_weight)\n",
    "                self.sigma[j] = self.update_cov(weight_j, sum_of_weight)\n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "54975b0d-6077-4f6a-bec6-3e493a5b1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignments(means, data, k, distance_calculation):\n",
    "    assignments = [[] for i in range(0,k)]\n",
    "    for idx, data_point in enumerate(data):\n",
    "        distances = [distance_calculation(data_point, m) for m in means]\n",
    "        optimal_cluster_id = distances.index(min(distances))\n",
    "        #print(f\" data point {data_point} -> optimal {optimal_cluster_id} = {means[optimal_cluster_id]}\")\n",
    "        assignments[optimal_cluster_id].append(idx)\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e2595d4-ef84-476b-8246-b7e6d6e706dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.13111206],\n",
       "       [1.93597506],\n",
       "       [2.85140955]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faux_data, N, d, a = read_data(2)\n",
    "test_gmm = GMM(faux_data, 3, N, d)\n",
    "test_gmm.avg_means_over_runs(n_runs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1bec2528-3393-459e-bd6a-c2e1dec9baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_std_dev_euclidean(means, data, k, N, dimension):\n",
    "    assignments = get_assignments(means, data, k, distance_between_points)\n",
    "    std_dev = []\n",
    "    for idx, cluster in enumerate(assignments):\n",
    "        s = 0\n",
    "        for idx_c, data_point in enumerate(cluster):\n",
    "            if dimension == 1:\n",
    "                s += math.sqrt((means[idx] - data_point) * (means[idx] - data_point))\n",
    "            else:\n",
    "                x = 0\n",
    "                for i in range(0, dimension):\n",
    "                    x += (means[idx][i] - data_point[i])*(means[idx][i] - data_point[i])\n",
    "                s+= math.sqrt(x)\n",
    "        std_dev.append(math.sqrt(s / N))\n",
    "    return std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b6a6e531-6a87-4c3e-a7e7-cc1369d5dcf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set: Experiment1\n",
      "S 3 | spacing 0.5 | k 2\n",
      "Nominal means [0.5 1.  1.5]\n",
      "Results for 2 | [[0.51399927]\n",
      " [1.34777996]]\n",
      "Standard Deviations [16.15282824684679, 15.41645156765033]\n",
      "Mean Standard Deviation across 2 clusters: 15.784639907248561\n",
      "Likelihood of pairs 0.3617847138855542\n",
      "\n",
      "Data Set: Experiment1\n",
      "S 3 | spacing 0.5 | k 3\n",
      "Nominal means [0.5 1.  1.5]\n",
      "Results for 3 | [[0.24784608]\n",
      " [1.00481029]\n",
      " [1.56320183]]\n",
      "Standard Deviations [14.178323043930078, 10.777051578280236, 13.469282005187067]\n",
      "Mean Standard Deviation across 3 clusters: 12.808218875799128\n",
      "Likelihood of pairs 0.3521374670086614\n",
      "\n",
      "Data Set: Experiment1\n",
      "S 3 | spacing 0.5 | k 6\n",
      "Nominal means [0.5 1.  1.5]\n",
      "Results for 6 | [[-0.0801099 ]\n",
      " [ 0.45861245]\n",
      " [ 0.79993799]\n",
      " [ 1.10102125]\n",
      " [ 1.37062543]\n",
      " [ 1.97659532]]\n",
      "Standard Deviations [11.643227579317442, 8.100897847227715, 7.874135345617686, 7.151676976617444, 7.698980529634323, 11.179028908539212]\n",
      "Mean Standard Deviation across 6 clusters: 8.941324531158969\n",
      "Likelihood of pairs 0.3355699081947345\n",
      "\n",
      "Data Set: Experiment1\n",
      "S 3 | spacing 0.5 | k 8\n",
      "Nominal means [0.5 1.  1.5]\n",
      "Results for 8 | [[-0.28062941]\n",
      " [ 0.33297903]\n",
      " [ 0.59631527]\n",
      " [ 0.84667966]\n",
      " [ 1.04165303]\n",
      " [ 1.25599123]\n",
      " [ 1.55538003]\n",
      " [ 2.17902252]]\n",
      "Standard Deviations [10.566250590726746, 7.907615166480381, 6.5768171827963355, 6.713776793334518, 6.007141671685779, 6.323169519473982, 7.923503729824485, 9.86032381417709]\n",
      "Mean Standard Deviation across 8 clusters: 7.734824808562415\n",
      "Likelihood of pairs 0.36449650819610496\n",
      "\n",
      "Data Set: Experiment2\n",
      "S 3 | spacing 1 | k 2\n",
      "Nominal means [1. 2. 3.]\n",
      "Results for 2 | [[1.373482  ]\n",
      " [2.53372832]]\n",
      "Standard Deviations [15.393191449992008, 16.142269359863036]\n",
      "Mean Standard Deviation across 2 clusters: 15.767730404927523\n",
      "Likelihood of pairs 0.40208957146076824\n",
      "\n",
      "Data Set: Experiment2\n",
      "S 3 | spacing 1 | k 3\n",
      "Nominal means [1. 2. 3.]\n",
      "Results for 3 | [[1.12205406]\n",
      " [1.95330682]\n",
      " [2.93022238]]\n",
      "Standard Deviations [13.512528508723024, 11.34891363190248, 13.642118569158535]\n",
      "Mean Standard Deviation across 3 clusters: 12.83452023659468\n",
      "Likelihood of pairs 0.43417166322194256\n",
      "\n",
      "Data Set: Experiment2\n",
      "S 3 | spacing 1 | k 6\n",
      "Nominal means [1. 2. 3.]\n",
      "Results for 6 | [[0.75295865]\n",
      " [1.37423932]\n",
      " [1.82522717]\n",
      " [2.12545019]\n",
      " [2.48881696]\n",
      " [3.47137214]]\n",
      "Standard Deviations [11.531337158782021, 7.530908858793441, 7.199517361532292, 7.307663756513577, 9.396388922222272, 10.690581858724029]\n",
      "Mean Standard Deviation across 6 clusters: 8.942732986094606\n",
      "Likelihood of pairs 0.39054873841625204\n",
      "\n",
      "Data Set: Experiment2\n",
      "S 3 | spacing 1 | k 8\n",
      "Nominal means [1. 2. 3.]\n",
      "Results for 8 | [[0.52342475]\n",
      " [1.12554529]\n",
      " [1.45999225]\n",
      " [1.73516385]\n",
      " [2.09646763]\n",
      " [2.37817927]\n",
      " [2.72572183]\n",
      " [3.68546848]]\n",
      "Standard Deviations [10.050516669545877, 7.219509673506726, 5.947639915597517, 6.755528064818799, 7.045073728084027, 6.794589844055133, 8.690019163544472, 9.593756085430972]\n",
      "Mean Standard Deviation across 8 clusters: 7.76207914307294\n",
      "Likelihood of pairs 0.4364256033072522\n",
      "\n",
      "Data Set: Experiment3\n",
      "S 3 | spacing 1.5 | k 2\n",
      "Nominal means [1.5 3.  4.5]\n",
      "Results for 2 | [[1.95944946]\n",
      " [3.85427252]]\n",
      "Standard Deviations [15.814810612763253, 15.700204666084934]\n",
      "Mean Standard Deviation across 2 clusters: 15.757507639424094\n",
      "Likelihood of pairs 0.5531325301204819\n",
      "\n",
      "Data Set: Experiment3\n",
      "S 3 | spacing 1.5 | k 3\n",
      "Nominal means [1.5 3.  4.5]\n",
      "Results for 3 | [[1.68237697]\n",
      " [2.87078546]\n",
      " [4.11315219]]\n",
      "Standard Deviations [13.433094456121983, 11.44801220409348, 13.604987360521173]\n",
      "Mean Standard Deviation across 3 clusters: 12.828698006912212\n",
      "Likelihood of pairs 0.5356302835798854\n",
      "\n",
      "Data Set: Experiment3\n",
      "S 3 | spacing 1.5 | k 6\n",
      "Nominal means [1.5 3.  4.5]\n",
      "Results for 6 | [[1.41515357]\n",
      " [2.10009652]\n",
      " [2.68913735]\n",
      " [3.18376394]\n",
      " [3.76492762]\n",
      " [4.40674392]]\n",
      "Standard Deviations [11.340258245168224, 8.032389854668308, 7.824503679577465, 7.360198436378985, 8.23474163795635, 10.966692652732954]\n",
      "Mean Standard Deviation across 6 clusters: 8.959797417747046\n",
      "Likelihood of pairs 0.5372973278547177\n",
      "\n",
      "Data Set: Experiment3\n",
      "S 3 | spacing 1.5 | k 8\n",
      "Nominal means [1.5 3.  4.5]\n",
      "Results for 8 | [[1.30049932]\n",
      " [1.88534864]\n",
      " [2.29519935]\n",
      " [2.68699308]\n",
      " [3.16577266]\n",
      " [3.59027289]\n",
      " [4.01932188]\n",
      " [4.51329418]]\n",
      "Standard Deviations [10.708001174364583, 6.820272808471765, 6.426532319720734, 7.184909651858782, 6.712444762349029, 6.759492845585287, 6.715309148666363, 10.327639055288577]\n",
      "Mean Standard Deviation across 8 clusters: 7.70682522078814\n",
      "Likelihood of pairs 0.5294343190685271\n",
      "\n",
      "Data Set: Experiment4\n",
      "S 3 | spacing 2 | k 2\n",
      "Nominal means [2. 4. 6.]\n",
      "Results for 2 | [[2.73101906]\n",
      " [5.15633971]]\n",
      "Standard Deviations [15.304135809950548, 16.165260325444486]\n",
      "Mean Standard Deviation across 2 clusters: 15.734698067697517\n",
      "Likelihood of pairs 0.49391025641025643\n",
      "\n",
      "Data Set: Experiment4\n",
      "S 3 | spacing 2 | k 3\n",
      "Nominal means [2. 4. 6.]\n",
      "Results for 3 | [[2.18025944]\n",
      " [4.0084817 ]\n",
      " [5.68403619]]\n",
      "Standard Deviations [12.748057640542937, 12.578210828109444, 13.221493988829756]\n",
      "Mean Standard Deviation across 3 clusters: 12.849254152494046\n",
      "Likelihood of pairs 0.6393652643682928\n",
      "\n",
      "Data Set: Experiment4\n",
      "S 3 | spacing 2 | k 6\n",
      "Nominal means [2. 4. 6.]\n",
      "Results for 6 | [[1.45364414]\n",
      " [3.02221633]\n",
      " [3.71957387]\n",
      " [4.0815219 ]\n",
      " [4.81428553]\n",
      " [6.27946906]]\n",
      "Standard Deviations [9.899196217333099, 9.725566595314683, 6.287253438095495, 7.541392659480099, 9.84449592586621, 10.471668443587838]\n",
      "Mean Standard Deviation across 6 clusters: 8.961595546612903\n",
      "Likelihood of pairs 0.6398218531677179\n",
      "\n",
      "Data Set: Experiment4\n",
      "S 3 | spacing 2 | k 8\n",
      "Nominal means [2. 4. 6.]\n",
      "Results for 8 | [[1.26568344]\n",
      " [2.78943255]\n",
      " [3.35124466]\n",
      " [3.74077978]\n",
      " [4.11054716]\n",
      " [4.63894637]\n",
      " [5.42371765]\n",
      " [6.36707474]]\n",
      "Standard Deviations [9.104663450627296, 8.799028432736579, 6.63275521292042, 5.410668246497327, 6.858550432750944, 7.463535010036284, 8.403373104224176, 9.41197069676675]\n",
      "Mean Standard Deviation across 8 clusters: 7.760568073319972\n",
      "Likelihood of pairs 0.6571908020562154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment_1_part_1\n",
    "standard_dev = 1\n",
    "S = 3\n",
    "spacing = [0.5, 1, 1.5, 2]\n",
    "k_varied = [2, 3, 6, 8]\n",
    "r_exp1 = []\n",
    "std_dev_exp1 = []\n",
    "avg_std_dev_exp1 = []\n",
    "lop_exp_1 = []\n",
    "for idx, space in enumerate(spacing):\n",
    "    for k in k_varied:\n",
    "        data, N, d, a = read_data(idx+1)\n",
    "        clf = GMM(data, k, N, d)\n",
    "        results = clf.avg_means_over_runs()\n",
    "        print(f\"S {S} | spacing {space} | k {k}\")\n",
    "        print(f\"Nominal means {np.unique(a)}\")\n",
    "        print(f\"Results for {k} | {results}\")\n",
    "        r_exp1.append(results)\n",
    "        s_d = calculate_std_dev_euclidean(results, data, k, N,d)\n",
    "        std_dev_exp1.append(s_d)\n",
    "        mean_assignments = get_assignments(results, data, k, simple_distance)\n",
    "        #print(mean_assignments)\n",
    "        lop = likelihood_of_pairs(mean_assignments, a)\n",
    "        print(f\"Standard Deviations {s_d}\")\n",
    "        print(f\"Mean Standard Deviation across {k} clusters: {np.mean(s_d)}\")\n",
    "        print(f\"Likelihood of pairs {lop}\")\n",
    "        lop_exp_1.append(lop)\n",
    "        \n",
    "        print()\n",
    "        avg_std_dev_exp1.append(np.mean(s_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b36efaa8-dfe4-4622-9166-5509a59c94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_distance(a,b):\n",
    "    return (a-b)*(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "142bdcc4-ccb2-4c5a-af03-7087550d03fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set: Experiment5\n",
      "S 5 | spacing 0.5\n",
      "Nominal means [0.5 1.  1.5 2.  2.5]\n",
      "Results for 5 | [[0.29593371]\n",
      " [1.10327514]\n",
      " [1.48116521]\n",
      " [2.00738497]\n",
      " [2.64846231]]\n",
      "Standard Deviations [11.220593595672932, 9.20146891126965, 8.65180833978739, 9.08937496038308, 11.400113486215272]\n",
      "Mean Standard Deviation across 5 clusters: 9.912671858665664\n",
      "Likelihood of pairs 0.2692805079701791\n",
      "\n",
      "Data Set: Experiment6\n",
      "S 5 | spacing 1\n",
      "Nominal means [1. 2. 3. 4. 5.]\n",
      "Results for 5 | [[1.13506564]\n",
      " [2.21359793]\n",
      " [3.21995381]\n",
      " [3.79251902]\n",
      " [4.46535987]]\n",
      "Standard Deviations [10.875587094071161, 9.261709927731285, 9.257948360892572, 7.764061619512445, 12.103472461950647]\n",
      "Mean Standard Deviation across 5 clusters: 9.85255589283162\n",
      "Likelihood of pairs 0.36781003311452637\n",
      "\n",
      "Data Set: Experiment7\n",
      "S 5 | spacing 1.5\n",
      "Nominal means [1.5 3.  4.5 6.  7.5]\n",
      "Results for 5 | [[1.32091365]\n",
      " [3.41569929]\n",
      " [4.43383467]\n",
      " [5.3888025 ]\n",
      " [7.09299827]]\n",
      "Standard Deviations [10.440178373886376, 9.884808771144554, 8.133302004299875, 9.384982875624425, 11.58138270998418]\n",
      "Mean Standard Deviation across 5 clusters: 9.884930946987883\n",
      "Likelihood of pairs 0.47224121155564236\n",
      "\n",
      "Data Set: Experiment8\n",
      "S 5 | spacing 2\n",
      "Nominal means [ 2.  4.  6.  8. 10.]\n",
      "Results for 5 | [[2.20971031]\n",
      " [4.8088334 ]\n",
      " [6.00929545]\n",
      " [7.13218328]\n",
      " [9.50358377]]\n",
      "Standard Deviations [10.827877344501557, 10.03816970301919, 7.838614963498995, 9.900880322496967, 10.775650822427183]\n",
      "Mean Standard Deviation across 5 clusters: 9.876238631188778\n",
      "Likelihood of pairs 0.52374859246517\n",
      "\n",
      "Data Set: Experiment9\n",
      "S 10 | spacing 0.5\n",
      "Nominal means [0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n",
      "Results for 10 | [[1.05978346]\n",
      " [1.31651068]\n",
      " [1.68642015]\n",
      " [2.14574188]\n",
      " [2.55974146]\n",
      " [2.89200202]\n",
      " [3.31564815]\n",
      " [3.86800481]\n",
      " [4.2929199 ]\n",
      " [4.6596083 ]]\n",
      "Standard Deviations [10.026522970383624, 4.762055697502353, 5.840357250074376, 6.585301428769011, 5.908104485756457, 5.69171220960368, 7.358701532255745, 6.631808167221782, 5.742843644621832, 9.878276935053139]\n",
      "Mean Standard Deviation across 10 clusters: 6.842568432124199\n",
      "Likelihood of pairs 0.1613784245093895\n",
      "\n",
      "Data Set: Experiment10\n",
      "S 10 | spacing 1\n",
      "Nominal means [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "Results for 10 | [[1.10101218]\n",
      " [2.39601682]\n",
      " [3.41524217]\n",
      " [4.18914704]\n",
      " [4.90224468]\n",
      " [5.59294801]\n",
      " [6.25930328]\n",
      " [7.04551814]\n",
      " [8.08212186]\n",
      " [9.73190874]]\n",
      "Standard Deviations [8.573502737214913, 7.108812155876158, 6.7084686772479944, 6.242134773507812, 6.573044818113668, 5.275718146685225, 6.207399742002665, 7.106891258987693, 7.274399251695628, 8.557375620255547]\n",
      "Mean Standard Deviation across 10 clusters: 6.962774718158729\n",
      "Likelihood of pairs 0.26429357512899443\n",
      "\n",
      "Data Set: Experiment11\n",
      "S 10 | spacing 1.5\n",
      "Nominal means [ 1.5  3.   4.5  6.   7.5  9.  10.5 12.  13.5 15. ]\n",
      "Results for 10 | [[ 1.93756369]\n",
      " [ 4.05873795]\n",
      " [ 5.76090476]\n",
      " [ 7.12615506]\n",
      " [ 8.12245598]\n",
      " [ 8.67368805]\n",
      " [ 9.41073047]\n",
      " [10.53119864]\n",
      " [12.13152947]\n",
      " [14.27414089]]\n",
      "Standard Deviations [8.354754837359618, 8.288784766248186, 6.893747722867902, 6.346921475454779, 5.080934712533851, 4.498781103107774, 5.710017733701917, 6.633574972614886, 7.677465696627007, 9.134123848085178]\n",
      "Mean Standard Deviation across 10 clusters: 6.861910686860111\n",
      "Likelihood of pairs 0.4110811780856567\n",
      "\n",
      "Data Set: Experiment12\n",
      "S 10 | spacing 2\n",
      "Nominal means [ 2.  4.  6.  8. 10. 12. 14. 16. 18. 20.]\n",
      "Results for 10 | [[ 2.40469252]\n",
      " [ 5.48070764]\n",
      " [ 7.80216943]\n",
      " [ 9.54421011]\n",
      " [10.88350447]\n",
      " [11.73618781]\n",
      " [12.83085682]\n",
      " [14.50387628]\n",
      " [16.68833654]\n",
      " [19.60947032]]\n",
      "Standard Deviations [8.623208467673214, 8.376339647100071, 7.290018223648989, 5.531856452722354, 5.191853158381931, 4.46344529755811, 5.536543843775549, 6.489734885738201, 8.131798053089744, 8.627688991434374]\n",
      "Mean Standard Deviation across 10 clusters: 6.826248702112254\n",
      "Likelihood of pairs 0.5013232388618082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment_1_Part_2\n",
    "exp_num = 4\n",
    "generators = [5, 10]\n",
    "for S in generators:\n",
    "    for space in spacing:\n",
    "        exp_num+=1\n",
    "        data, N, d, a = read_data(exp_num)\n",
    "        clf = GMM(data, S, N, d)\n",
    "        results = clf.avg_means_over_runs()\n",
    "        print(f\"S {S} | spacing {space}\")\n",
    "        print(f\"Nominal means {np.unique(a)}\")\n",
    "        print(f\"Results for {S} | {results}\")\n",
    "        #r_exp1.append(results)\n",
    "        s_d = calculate_std_dev_euclidean(results, data, S, N,d)\n",
    "        #std_dev_exp1.append(s_d)\n",
    "        mean_assignments = get_assignments(results, data, S, simple_distance)\n",
    "        #print(mean_assignments)\n",
    "        lop = likelihood_of_pairs(mean_assignments, a)\n",
    "        print(f\"Standard Deviations {s_d}\")\n",
    "        print(f\"Mean Standard Deviation across {S} clusters: {np.mean(s_d)}\")\n",
    "        print(f\"Likelihood of pairs {lop}\")\n",
    "        #lop_exp_1.append(lop)\n",
    "        print()\n",
    "        #avg_std_dev_exp1.append(np.mean(s_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8d359e19-1f53-484d-a769-6c2826b8c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set: Experiment_2_1\n",
      " S 5 | std_dev 1\n",
      "Nominal means [ 1.  4.  7. 10. 13.]\n",
      "Results for 5 | [[ 1.23013747]\n",
      " [ 4.695164  ]\n",
      " [ 7.36690454]\n",
      " [ 9.7786939 ]\n",
      " [13.1317965 ]]\n",
      "Standard Deviations [10.644488696925826, 10.0752844886738, 9.355521990043218, 9.82159375215016, 9.677831961726827]\n",
      "Mean Standard Deviation across 5 clusters: 9.914944177903967\n",
      "Likelihood of pairs 0.7912872166065443\n",
      "\n",
      "Data Set: Experiment_2_2\n",
      " S 5 | std_dev 2\n",
      "Nominal means [ 1.  4.  7. 10. 13.]\n",
      "Results for 5 | [[ 1.27031469]\n",
      " [ 5.11717866]\n",
      " [ 7.24940326]\n",
      " [ 9.44078634]\n",
      " [12.09474481]]\n",
      "Standard Deviations [11.260557313633784, 9.56058241188646, 7.361254433508194, 9.894055594110354, 11.058404667817326]\n",
      "Mean Standard Deviation across 5 clusters: 9.826970884191223\n",
      "Likelihood of pairs 0.47492882605449793\n",
      "\n",
      "Data Set: Experiment_2_3\n",
      " S 5 | std_dev 3\n",
      "Nominal means [ 1.  4.  7. 10. 13.]\n",
      "Results for 5 | [[ 2.25451907]\n",
      " [ 4.78344167]\n",
      " [ 7.03576942]\n",
      " [ 8.77827951]\n",
      " [12.63827515]]\n",
      "Standard Deviations [11.657037975868755, 9.12129095481005, 8.292743837913306, 9.45446506618491, 10.733133496934112]\n",
      "Mean Standard Deviation across 5 clusters: 9.851734266342225\n",
      "Likelihood of pairs 0.3966685177829756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 2\n",
    "std_dev = [1,2,3]\n",
    "k=5\n",
    "for idx, s_dev in enumerate(std_dev):\n",
    "    data, N, d, a = read_data(f\"_2_{idx+1}\")\n",
    "    clf = GMM(data, 5, N, d)\n",
    "    results = clf.avg_means_over_runs()\n",
    "    print(f\" S {5} | std_dev {s_dev}\")\n",
    "    print(f\"Nominal means {np.unique(a)}\")\n",
    "    print(f\"Results for {k} | {results}\")\n",
    "    #r_exp1.append(results)\n",
    "    s_d = calculate_std_dev_euclidean(results, data, k, N,d)\n",
    "    #std_dev_exp1.append(s_d)\n",
    "    mean_assignments = get_assignments(results, data, k, simple_distance)\n",
    "    #print(mean_assignments)\n",
    "    lop = likelihood_of_pairs(mean_assignments, a)\n",
    "    print(f\"Standard Deviations {s_d}\")\n",
    "    print(f\"Mean Standard Deviation across {k} clusters: {np.mean(s_d)}\")\n",
    "    print(f\"Likelihood of pairs {lop}\")\n",
    "    #lop_exp_1.append(lop)\n",
    "    print()\n",
    "    #avg_std_dev_exp1.append(np.mean(s_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e3b08617-443e-4851-ba9b-3d039eb0cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set: Experiment_3_1\n",
      "experiment 3\n",
      "Nominal means [1.   2.25 3.5  4.75 6.  ]\n",
      "Results for 5 | [[1.41539216]\n",
      " [2.42762337]\n",
      " [3.52037572]\n",
      " [4.49549109]\n",
      " [6.16347022]]\n",
      "Standard Deviations [11.767763572940378, 7.602093787129054, 8.05708551668375, 9.757348393636951, 11.806715720292631]\n",
      "Mean Standard Deviation across 5 clusters: 9.798201398136552\n",
      "Likelihood of pairs 0.3463370108524681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 3\n",
    "k=5\n",
    "data, N, d, a = read_data(f\"_3_1\")\n",
    "clf = GMM(data, 5, N, d)\n",
    "results = clf.avg_means_over_runs()\n",
    "print(f\"experiment 3\")\n",
    "print(f\"Nominal means {np.unique(a)}\")\n",
    "print(f\"Results for {k} | {results}\")\n",
    "#r_exp1.append(results)\n",
    "s_d = calculate_std_dev_euclidean(results, data, k, N,d)\n",
    "#std_dev_exp1.append(s_d)\n",
    "mean_assignments = get_assignments(results, data, k, simple_distance)\n",
    "#print(mean_assignments)\n",
    "lop = likelihood_of_pairs(mean_assignments, a)\n",
    "print(f\"Standard Deviations {s_d}\")\n",
    "print(f\"Mean Standard Deviation across {k} clusters: {np.mean(s_d)}\")\n",
    "print(f\"Likelihood of pairs {lop}\")\n",
    "#lop_exp_1.append(lop)\n",
    "print()\n",
    "#avg_std_dev_exp1.append(np.mean(s_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea745f7d-5cc4-4f7a-a44a-3f78606a7bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set: Experiment_4_100\n",
      "N 100\n",
      "Nominal means [1.   2.25 3.5  4.75 6.  ]\n",
      "Results for 5 | [[0.59139341]\n",
      " [2.51984854]\n",
      " [3.66748658]\n",
      " [4.83133308]\n",
      " [6.23952299]]\n",
      "Standard Deviations [3.2074343722882057, 3.1371998213967345, 2.6413163155794166, 3.1225758695711443, 3.026034676090677]\n",
      "Mean Standard Deviation across 5 clusters: 3.0269122109852353\n",
      "Likelihood of pairs 0.4787878787878788\n",
      "\n",
      "Data Set: Experiment_4_1000\n",
      "N 1000\n",
      "Nominal means [1.   2.25 3.5  4.75 6.  ]\n",
      "Results for 5 | [[0.95018427]\n",
      " [2.77064859]\n",
      " [3.3185119 ]\n",
      " [4.11339384]\n",
      " [5.78186937]]\n",
      "Standard Deviations [10.80060209387416, 9.27737005833878, 7.460386795047738, 9.563277130311604, 12.09070582019269]\n",
      "Mean Standard Deviation across 5 clusters: 9.838468379552994\n",
      "Likelihood of pairs 0.5376191989828353\n",
      "\n",
      "Data Set: Experiment_4_5000\n",
      "N 5000\n",
      "Nominal means [1.   2.25 3.5  4.75 6.  ]\n",
      "Results for 5 | [[1.21390002]\n",
      " [2.77797182]\n",
      " [3.5340977 ]\n",
      " [4.27399269]\n",
      " [5.94561974]]\n",
      "Standard Deviations [25.251666962278694, 21.671040254287742, 17.52023029676495, 21.139196705633804, 25.19638917965879]\n",
      "Mean Standard Deviation across 5 clusters: 22.1557046797248\n",
      "Likelihood of pairs 0.508183802020701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 4\n",
    "k = 5\n",
    "N = [100, 1000, 5000]\n",
    "for idx, val in enumerate(N):\n",
    "    exp_path = f\"_4_{val}\"\n",
    "    data, N, d, a = read_data(exp_path)\n",
    "    clf = GMM(data, 5, N, d)\n",
    "    results = clf.avg_means_over_runs()\n",
    "    print(f\"N {N}\")\n",
    "    print(f\"Nominal means {np.unique(a)}\")\n",
    "    print(f\"Results for {k} | {results}\")\n",
    "    s_d = calculate_std_dev_euclidean(results, data, k, N,d)\n",
    "    #std_dev_exp1.append(s_d)\n",
    "    mean_assignments = get_assignments(results, data, k, simple_distance)\n",
    "    #print(mean_assignments)\n",
    "    lop = likelihood_of_pairs(mean_assignments, a)\n",
    "    print(f\"Standard Deviations {s_d}\")\n",
    "    print(f\"Mean Standard Deviation across {k} clusters: {np.mean(s_d)}\")\n",
    "    print(f\"Likelihood of pairs {lop}\")\n",
    "    #lop_exp_1.append(lop)\n",
    "    print()\n",
    "    #avg_std_dev_exp1.append(np.mean(s_d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
